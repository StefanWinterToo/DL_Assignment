{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import the needed python packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import tensorflow as tf\r\n",
    "import keras\r\n",
    "import matplotlib as plt\r\n",
    "import seaborn as sb\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import scipy as sy\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load preprocessed Kaggle data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "file_train = open(\"data/training_dataset.pickle\",'rb')\r\n",
    "trainingdata = pickle.load(file_train)\r\n",
    "train_data, train_label = trainingdata['data'], trainingdata['label']\r\n",
    "\r\n",
    "file_validation = open(\"data/validation_dataset.pickle\",'rb')\r\n",
    "validationdata = pickle.load(file_validation)\r\n",
    "valid_data, valid_label = validationdata['data'], validationdata['label']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a the baseline CNN model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# create a sequential model\r\n",
    "model = tf.keras.Sequential()\r\n",
    "\r\n",
    "# add layers\r\n",
    "model.add(tf.keras.layers.Input((100,100,3)))\r\n",
    "model.add(tf.keras.layers.Conv2D(16, (3,3), activation='relu'))\r\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\r\n",
    "model.add(tf.keras.layers.Conv2D(16, (3,3), activation='relu'))\r\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\r\n",
    "model.add(tf.keras.layers.Flatten())\r\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\r\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 98, 98, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 49, 49, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 47, 47, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 23, 23, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8464)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                541760    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 544,593\n",
      "Trainable params: 544,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "le = LabelEncoder()\r\n",
    "le.fit(train_label)\r\n",
    "train_label = le.transform(train_label)\r\n",
    "\r\n",
    "le.fit(valid_label)\r\n",
    "valid_label = le.transform(valid_label)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "print(train_label)\r\n",
    "print(valid_label)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# Training the network\r\n",
    "model.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\r\n",
    "model.fit(x = train_data, y = train_label, batch_size = 64, epochs = 10)\r\n",
    "test_loss, test_acc = model.evaluate(x = valid_data, y = valid_label)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "174/174 [==============================] - 45s 255ms/step - loss: 0.4486 - accuracy: 0.7961\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - 46s 265ms/step - loss: 0.3779 - accuracy: 0.8307\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 49s 279ms/step - loss: 0.3332 - accuracy: 0.8551\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 48s 276ms/step - loss: 0.2948 - accuracy: 0.8760\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 36s 208ms/step - loss: 0.2701 - accuracy: 0.8875\n",
      "Epoch 6/10\n",
      "174/174 [==============================] - 39s 223ms/step - loss: 0.2429 - accuracy: 0.9013\n",
      "Epoch 7/10\n",
      "174/174 [==============================] - 38s 218ms/step - loss: 0.2128 - accuracy: 0.9131\n",
      "Epoch 8/10\n",
      "174/174 [==============================] - 37s 211ms/step - loss: 0.1895 - accuracy: 0.9215\n",
      "Epoch 9/10\n",
      "174/174 [==============================] - 38s 216ms/step - loss: 0.1607 - accuracy: 0.9377\n",
      "Epoch 10/10\n",
      "174/174 [==============================] - 37s 215ms/step - loss: 0.1351 - accuracy: 0.9490\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.3536 - accuracy: 0.8718\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "model.save(\"model/baseline\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: model/baseline\\assets\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "9ff7ad65fd33a767da5485be53880310ae0b5bdc0d199936e60539568ae78205"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}